{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GirijaKondapally/Girija_INFO5731_-Fall2023/blob/main/Kondapally_Exercise_03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdRwkJBn70nX"
      },
      "source": [
        "## The third In-class-exercise (due on 11:59 PM 10/08/2023, 40 points in total)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2htC-oV70ne"
      },
      "source": [
        "The purpose of this exercise is to understand text representation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARqm7u6B70ne"
      },
      "source": [
        "Question 1 (10 points): Describe an interesting text classification or text mining task and explain what kind of features might be useful for you to build the machine learning model. List your features and explain why these features might be helpful. You need to list at least five different types of features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VAZj4PHB70nf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "7b377c15-9b9c-4852-80e6-1339501bcbb5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nPlease write you answer here:\\nMy text classification task is to perform sentimental analysis of the customer reviews for a movie. Here i will be taking some sample\\nreviews in the form of a list as a sample reviews. So, I want to classify customer reviews based on the text content into good, negative, or neutral.\\nNow let us consider these five features that are listed below to perform the text classification task.\\n1.\\tBag of Words: BoW features track the frequency of words in reviews, allowing the model to determine whether certain words or phrases are associated with positive or negative .\\n2.\\tTerm Frequency-Inverse Document Frequency (TF-IDF): The relevance of terms in a document in relation to a corpus is represented by TF-IDF (Term Frequency-Inverse Document Frequency) characteristics. These features are beneficial because they draw attention to words or phrases that are particular to a given category.\\n3  \\tN-grams: Associated groups of 'n' words or characters taken from a text document are known as 'n-grams' in the field of text mining. They help with tasks like sentiment analysis, language modeling, and information retrieval by analyzing and modeling language patterns.\\n4.\\tSentiment Lexicons:it is used for the news items that can be evaluated using sentiment analyse the sentiment of the content.\\n5.\\tPart-of-Speech (POS) Tags: To mark the nouns, adjectives, and verbs that make up the grammatical structure of the text, use POS tagging.\\nIt is used because it may be possible to spot grammatical patterns in evaluations using POS features. For illustration, a review may be deemed positive if it contains many positive adjectives.\\n\\n\\n\\n\\n\\n\\n\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# Your answer here (no code for this question, write down your answer as detail as possible for the above questions):\n",
        "\n",
        "'''\n",
        "Please write you answer here:\n",
        "My text classification task is to perform sentimental analysis of the customer reviews for a movie. Here i will be taking some sample\n",
        "reviews in the form of a list as a sample reviews. So, I want to classify customer reviews based on the text content into good, negative, or neutral.\n",
        "Now let us consider these five features that are listed below to perform the text classification task.\n",
        "1.\tBag of Words: BoW features track the frequency of words in reviews, allowing the model to determine whether certain words or phrases are associated with positive or negative .\n",
        "2.\tTerm Frequency-Inverse Document Frequency (TF-IDF): The relevance of terms in a document in relation to a corpus is represented by TF-IDF (Term Frequency-Inverse Document Frequency) characteristics. These features are beneficial because they draw attention to words or phrases that are particular to a given category.\n",
        "3  \tN-grams: Associated groups of 'n' words or characters taken from a text document are known as 'n-grams' in the field of text mining. They help with tasks like sentiment analysis, language modeling, and information retrieval by analyzing and modeling language patterns.\n",
        "4.\tSentiment Lexicons:it is used for the news items that can be evaluated using sentiment analyse the sentiment of the content.\n",
        "5.\tPart-of-Speech (POS) Tags: To mark the nouns, adjectives, and verbs that make up the grammatical structure of the text, use POS tagging.\n",
        "It is used because it may be possible to spot grammatical patterns in evaluations using POS features. For illustration, a review may be deemed positive if it contains many positive adjectives.\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEUjBE6C70nf"
      },
      "source": [
        "Question 2 (10 points): Write python code to extract these features you discussed above. You can collect a few sample text data for the feature extraction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "EoQX5s4O70nf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61980d06-a3f2-42fa-ed78-2f6dac44b60c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# You code here (Please add comments in the code):\n",
        "import nltk\n",
        "import spacy\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "sample_reviews = [\n",
        "    \"This movie is fabulous!!!. I am gona watch it again.\",\n",
        "    \"This movie is a disaster. Not recommneded.\",\n",
        "    \"This movie is an average movie. could be a one time watch.\",\n",
        "]\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "nltk.download(\"vader_lexicon\")\n",
        "S_I_A = SentimentIntensityAnalyzer()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Bag of Words (BoW)\n",
        "cv = CountVectorizer(stop_words=stopwords.words(\"english\"))\n",
        "Bow_feat = cv.fit_transform(sample_reviews)\n",
        "Bow_df = pd.DataFrame(Bow_feat.toarray(), columns=cv.get_feature_names_out())\n",
        "print(\"Bag of Words (BoW):\\n\", Bow_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0wCXu_WlFGw",
        "outputId": "73d6e4bc-2418-4a1a-e176-fad5b376228b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bag of Words (BoW):\n",
            "    average  could  disaster  fabulous  gona  movie  one  recommneded  time  \\\n",
            "0        0      0         0         1     1      1    0            0     0   \n",
            "1        0      0         1         0     0      1    0            1     0   \n",
            "2        1      1         0         0     0      2    1            0     1   \n",
            "\n",
            "   watch  \n",
            "0      1  \n",
            "1      0  \n",
            "2      1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Term Frequency-Inverse Document Frequency (TF-IDF)\n",
        "tfidf_vect = TfidfVectorizer(stop_words=stopwords.words(\"english\"))\n",
        "tfidf_feat = tfidf_vect.fit_transform(sample_reviews )\n",
        "tfidf_df = pd.DataFrame(tfidf_feat.toarray(), columns=tfidf_vect.get_feature_names_out())\n",
        "print(\"\\nTF-IDF:\\n\", tfidf_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7O-tKrTlHJr",
        "outputId": "70980906-c975-4c30-9347-752fee68f903"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TF-IDF:\n",
            "     average     could  disaster  fabulous      gona     movie       one  \\\n",
            "0  0.000000  0.000000  0.000000  0.584483  0.584483  0.345205  0.000000   \n",
            "1  0.000000  0.000000  0.652491  0.000000  0.000000  0.385372  0.000000   \n",
            "2  0.409146  0.409146  0.000000  0.000000  0.000000  0.483296  0.409146   \n",
            "\n",
            "   recommneded      time     watch  \n",
            "0     0.000000  0.000000  0.444514  \n",
            "1     0.652491  0.000000  0.000000  \n",
            "2     0.000000  0.409146  0.311166  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sentiment Lexicons (VADER sentiment scores)\n",
        "sent_scores = [S_I_A.polarity_scores(text) for text in sample_reviews]\n",
        "sent_df = pd.DataFrame(sent_scores)\n",
        "print(\"\\nSentiment Lexicons (VADER):\\n\", sent_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WPpfI-elLKx",
        "outputId": "48792a44-a3cf-4ff0-f50c-600461cb71ba"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sentiment Lexicons (VADER):\n",
            "      neg    neu  pos  compound\n",
            "0  0.000  1.000  0.0    0.0000\n",
            "1  0.451  0.549  0.0   -0.6249\n",
            "2  0.000  1.000  0.0    0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#N-grams\n",
        "ngram_vect = CountVectorizer(ngram_range=(1, 2), stop_words=stopwords.words(\"english\"))\n",
        "ngram_feat = ngram_vect.fit_transform(sample_reviews)\n",
        "ngram_df = pd.DataFrame(ngram_feat.toarray(), columns=ngram_vect.get_feature_names_out())\n",
        "print(\"\\nN-grams:\\n\", ngram_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptyTT_JmlSEL",
        "outputId": "8c5fd4a8-ff4e-46f5-c829-dc93aff2bd70"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "N-grams:\n",
            "    average  average movie  could  could one  disaster  disaster recommneded  \\\n",
            "0        0              0      0          0         0                     0   \n",
            "1        0              0      0          0         1                     1   \n",
            "2        1              1      1          1         0                     0   \n",
            "\n",
            "   fabulous  fabulous gona  gona  gona watch  ...  movie average  movie could  \\\n",
            "0         1              1     1           1  ...              0            0   \n",
            "1         0              0     0           0  ...              0            0   \n",
            "2         0              0     0           0  ...              1            1   \n",
            "\n",
            "   movie disaster  movie fabulous  one  one time  recommneded  time  \\\n",
            "0               0               1    0         0            0     0   \n",
            "1               1               0    0         0            1     0   \n",
            "2               0               0    1         1            0     1   \n",
            "\n",
            "   time watch  watch  \n",
            "0           0      1  \n",
            "1           0      0  \n",
            "2           1      1  \n",
            "\n",
            "[3 rows x 21 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Part-of-Speech (POS) Tags\n",
        "tags = [nltk.pos_tag(nltk.word_tokenize(text)) for text in sample_reviews]\n",
        "print(\"\\nPart-of-Speech (POS) Tags:\\n\", tags)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSE3dhSSlYLR",
        "outputId": "1dccda31-f2c5-45a9-81ee-615ab6324d3d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Part-of-Speech (POS) Tags:\n",
            " [[('This', 'DT'), ('movie', 'NN'), ('is', 'VBZ'), ('fabulous', 'JJ'), ('!', '.'), ('!', '.'), ('!', '.'), ('.', '.'), ('I', 'PRP'), ('am', 'VBP'), ('gona', 'JJ'), ('watch', 'NN'), ('it', 'PRP'), ('again', 'RB'), ('.', '.')], [('This', 'DT'), ('movie', 'NN'), ('is', 'VBZ'), ('a', 'DT'), ('disaster', 'NN'), ('.', '.'), ('Not', 'RB'), ('recommneded', 'VBN'), ('.', '.')], [('This', 'DT'), ('movie', 'NN'), ('is', 'VBZ'), ('an', 'DT'), ('average', 'JJ'), ('movie', 'NN'), ('.', '.'), ('could', 'MD'), ('be', 'VB'), ('a', 'DT'), ('one', 'CD'), ('time', 'NN'), ('watch', 'NN'), ('.', '.')]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oSK4soH70nf"
      },
      "source": [
        "Question 3 (10 points): Use any of the feature selection methods mentioned in this paper \"Deng, X., Li, Y., Weng, J., & Zhang, J. (2019). Feature selection for text classification: A review. Multimedia Tools & Applications, 78(3).\"\n",
        "\n",
        "Select the most important features you extracted above, rank the features based on their importance in the descending order."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "2CRuXfV570ng",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eca1112b-fc89-4572-b37d-e754f0c78552"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature: is, Importance: 0.1059\n",
            "Feature: again, Importance: 0.0882\n",
            "Feature: watch, Importance: 0.0824\n",
            "Feature: it, Importance: 0.0706\n",
            "Feature: movie, Importance: 0.0706\n",
            "Feature: time, Importance: 0.0647\n",
            "Feature: average, Importance: 0.0529\n",
            "Feature: one, Importance: 0.0529\n",
            "Feature: this, Importance: 0.0529\n",
            "Feature: an, Importance: 0.0471\n"
          ]
        }
      ],
      "source": [
        "# You code here (Please add comments in the code):\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import pandas as pd\n",
        "\n",
        "labels = ['fabulous', 'disaster', 'average']\n",
        "\n",
        "label_dic = {label: idx for idx, label in enumerate(labels)}\n",
        "numlabels = [label_dic[label] for label in labels]\n",
        "\n",
        "# Creating a new TF-IDF vectorizer\n",
        "tfidf_vect = TfidfVectorizer()\n",
        "tfidf_feat = tfidf_vect.fit_transform(sample_reviews)\n",
        "\n",
        "# training Random Forest classifier\n",
        "rforest_cf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rforest_cf.fit(tfidf_feat, numlabels)\n",
        "\n",
        "feat_imp = rforest_cf.feature_importances_\n",
        "\n",
        "featimp_df = pd.DataFrame({'Feature': tfidf_vect.get_feature_names_out(), 'Importance': feat_imp})\n",
        "\n",
        "sorted_feat = featimp_df.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "top_n = 10\n",
        "for idx, row in sorted_feat.head(top_n).iterrows():\n",
        "    print(f\"Feature: {row['Feature']}, Importance: {row['Importance']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nZGAOwl70ng"
      },
      "source": [
        "Question 4 (10 points): Write python code to rank the text based on text similarity. Based on the text data you used for question 2, design a query to match the most relevant docments. Please use the BERT model to represent both your query and the text data, then calculate the cosine similarity between the query and each text in your data. Rank the similary with descending order."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "b4HoWK-i70ng",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd67d503-b19e-464a-fa50-5a6f77b3f10e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.34.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.17.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n"
          ]
        }
      ],
      "source": [
        "pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "query = \"how is the movie\"\n",
        "\n",
        "modelname = \"bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(modelname)\n",
        "model = AutoModel.from_pretrained(modelname)\n",
        "\n",
        "def get_bert_embeddings(text):\n",
        "    inp = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    with torch.no_grad():\n",
        "        outputs_tokens = model(**inp)\n",
        "    op_embeddings = outputs_tokens.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "    return op_embeddings\n",
        "\n",
        "\n",
        "query_embeddings = get_bert_embeddings(query)\n",
        "review_embeddings= [get_bert_embeddings(text) for text in sample_reviews]\n",
        "\n",
        "similarities = cosine_similarity([query_embeddings ], review_embeddings)[0]\n",
        "\n",
        "ranking = sorted(enumerate(similarities ), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "\n",
        "print(\"Rankings:\")\n",
        "for rank, (index, similarity) in enumerate(ranking):\n",
        "    print(f\"Rank {rank + 1}: Similarity = {similarity:.4f}\")\n",
        "    print(f\"Text: {sample_reviews[index]}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hEzvXdglmTv",
        "outputId": "63738b42-4275-4d0a-e761-c4f48726e502"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rankings:\n",
            "Rank 1: Similarity = 0.6337\n",
            "Text: This movie is an average movie. could be a one time watch.\n",
            "\n",
            "Rank 2: Similarity = 0.6182\n",
            "Text: This movie is fabulous!!!. I am gona watch it again.\n",
            "\n",
            "Rank 3: Similarity = 0.5579\n",
            "Text: This movie is a disaster. Not recommneded.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "69BJFu7wmK05"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}